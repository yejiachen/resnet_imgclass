import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, load_model
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import Model
from keras.layers import Input, Dense

import matplotlib.pyplot as plt
import os
from os import listdir
from os.path import isfile, isdir, join
import numpy as np
import pandas as pd
import pickle
import cv2
import glob
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle


train_file = "/home/jovyan/self_practice/midterm/imgclass/flower_classification/train/"
test_file = "/home/jovyan/self_practice/midterm/imgclass/flower_classification/test/"
datadir='/home/jovyan/self_practice/midterm/imgclass/flower_classification/'

img_size = 224
labelmap=pd.read_csv(datadir+'mid_term_mapping.txt',names=['place','index'])
sortlabel=labelmap.sort('index')
targetlist=sortlabel.place.as_matrix().tolist()

x = []
y = []

for i,c in enumerate(targetlist):
    ff=glob.glob((datadir+'train/'+c+'/*jpg'))
    for f in ff:
        img=cv2.imread(f,1,)
        img200=cv2.resize(img,(img_size,img_size),3)
        iii=(np.reshape(img200,(img_size,img_size,3))).astype(float)
        iii2 = iii/256
        x.append(iii2)
        nn=np.zeros(5,dtype=float)
        nn[i]=1
        y.append(nn)

xx=np.array(x)
yy=np.array(y)

x_train_list, x_test_list, y_train, y_test = train_test_split(xx, yy, 
                                                              test_size=0.05,stratify = yy.argmax(axis = 1)) #random_state=42)

batch_size = 4
num_classes = 5
epochs = 200
save_dir = os.path.join(os.getcwd(), 'saved_models')
model_name = '0.0.0.10.h5'

model = keras.applications.resnet50.ResNet50(include_top=True, 
	weights='imagenet', input_tensor=None, input_shape=(224,224,3), pooling=None)
#print(model.summary())

# Get input

new_input1 = model.input
hidden_layer = model.layers[-2].output
new_output1 = Dense(2048, activation='selu') (hidden_layer)
model = Model(new_input1, new_output1)

new_input2 = model.input
new_output2 = Dropout(0.5) (model.output)
model = Model(new_input2, new_output2)

new_input3 = model.input
new_output3 = Dense(5, activation='softmax') (model.output)

model = Model(new_input3, new_output3)
print(model.summary())

# initiate Adam optimizer
opt = keras.optimizers.Adam()

# Let's train the model using Adam
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

print('Using real-time data augmentation.')
# This will do preprocessing and realtime data augmentation:
datagen = ImageDataGenerator(
    rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)
    width_shift_range=1,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=1,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=True,  # randomly flip images
    vertical_flip=False)  # randomly flip images


# Use ModelCheckpoint to save model and weights
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)
model_path = os.path.join(save_dir, model_name)
checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=0, mode='max')

# earlystop
earlystop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)

# Fit the model on the batches generated by datagen.flow().
model_history = model.fit_generator(datagen.flow(x_train_list, y_train,batch_size=batch_size),
                                    epochs=epochs,
                                    validation_data=(x_test_list, y_test),
                                    workers=4,
                                    callbacks=[checkpoint]
                                    #callbacks=[earlystop]
                                   )

model.save('saved_models/0.0.0.10.1.h5')

testdata=pd.read_csv(datadir+'submission.csv')
testdataindexlist=testdata.id.as_matrix().tolist()

x_t=[]
sz = img_size
for f in testdataindexlist:
    img=cv2.imread(datadir+'test/'+f+'.jpg',1)
    img200=cv2.resize(img,(sz,sz,),)
    iii=(np.reshape(img200,(sz,sz,3))).astype(float)/256
    x_t.append(iii)

        
x_test=np.array(x_t)

y_pred = model.predict(x_test, batch_size=4, verbose=1)
y_pred_argmax = y_pred.argmax(axis=-1)

testdatasheet=pd.read_csv(datadir+'submission.csv')
testdatasheet['class']=y_pred_argmax
testdatasheet.to_csv('score/0.0.0_10.csv', index=False)
